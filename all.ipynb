{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean the dataset\n",
    "data = pd.read_csv(\"train1.csv\")\n",
    "\n",
    "# Drop irrelevant columns and rows with missing target values\n",
    "data.drop(columns=['id', 'brand', 'model', 'engine'], inplace=True)\n",
    "data.dropna(subset=['price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transformation to 'price' to reduce skewness\n",
    "data['price'] = np.log1p(data['price'])\n",
    "\n",
    "# Create a new feature for vehicle age and drop 'model_year'\n",
    "data['vehicle_age'] = 2024 - data['model_year']\n",
    "data.drop(columns=['model_year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers in 'price' using the IQR method\n",
    "Q1, Q3 = data['price'].quantile([0.25, 0.75])\n",
    "IQR = Q3 - Q1\n",
    "lower_bound, upper_bound = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "data = data[(data['price'] >= lower_bound) & (data['price'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X, y = data.drop(columns=['price']), data['price']\n",
    "\n",
    "# Identify categorical columns (low cardinality) and numerical columns\n",
    "categorical_cols = [col for col in X.select_dtypes(include=['object']).columns if X[col].nunique() <= 3]\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numerical features (impute missing values, scale)\n",
    "num_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing pipeline for categorical features (impute and one-hot encode)\n",
    "cat_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both preprocessing pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_transformer, numerical_cols),\n",
    "    ('cat', cat_transformer, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost model\n",
    "xgboost = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Create a complete pipeline (preprocessing + model)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgboost)\n",
    "])\n",
    "\n",
    "# Hyperparameter grid for XGBoost tuning\n",
    "param_grid = {\n",
    "    'regressor__max_depth': [3, 5, 7],\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__subsample': [0.8, 0.9, 1.0],\n",
    "    'regressor__colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "Best Parameters: {'regressor__colsample_bytree': 0.8, 'regressor__learning_rate': 0.1, 'regressor__max_depth': 5, 'regressor__n_estimators': 300, 'regressor__subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics on log-transformed scale:\n",
      "  RMSE: 0.48\n",
      "  R2: 0.62\n",
      "Metrics on original scale:\n",
      "  RMSE: 26076.45\n",
      "  R2: 0.38\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics on log-transformed scale\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Metrics on log-transformed scale:\\n  RMSE: {rmse:.2f}\\n  R2: {r2:.2f}\")\n",
    "\n",
    "# Convert predictions and actual values back to the original scale\n",
    "y_test_actual = np.expm1(y_test)\n",
    "y_pred_actual = np.expm1(y_pred)\n",
    "\n",
    "# Calculate final metrics on the original scale\n",
    "final_mse = mean_squared_error(y_test_actual, y_pred_actual)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_r2 = r2_score(y_test_actual, y_pred_actual)\n",
    "\n",
    "print(f\"Metrics on original scale:\\n  RMSE: {final_rmse:.2f}\\n  R2: {final_r2:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
